{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Models:\n",
    "\n",
    "In this script we construct the models for utterance classification tested in our analysis. Specifically you will find here the implementation of several models:\n",
    "\n",
    "1. MLP (2 Hidden Layers) + Pre-Trained Static Embeddings\n",
    "2. MLP (2 Hidden Layers) + Pre-Trained Trainable Embeddings\n",
    "3. MLP + Pre-Trained Static Embeddings + Simple Attention Mechanism\n",
    "4. MLP + Pre-Trained Trainable Embeddings + Simple Attention Mechanism\n",
    "5. MLP + Pre Trained Static Embeddings + Differentiated Attention\n",
    "\n",
    "Additionally, you can find the models:\n",
    "\n",
    "6. MLP (1 Hidden Layer + Dropout) + Pre-Trained Static Embeddings\n",
    "7. MLP (1 Hidden Layer + Dropout) + Pre-Trained Trainable Embeddings\n",
    "\n",
    "Models 3 to 7 are compared in the article \"Automatic Content Analysis of Computer-Supported Collaborative Inquiry-Based Learning Using Deep Networks and Attention Mechanisms\" (Pablo Uribe, Abelino Jiménez, Roberto Araya, Joni Lämsä, Raija Hämäläinen, Jouni Viiri), while models 1 to 5 are compared in the article \"Deep Networks for Collaboration Analytics: Automatic Coding of Face-to-Face Conversations in a Computer-Supported Inquiry-Based Learning Context\" (Joni Lämsä, Pablo Uribe, Abelino Jiménez, Raija Hämäläinen, Daniela Caballero, Roberto Araya). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import num2words\n",
    "from tensorflow.keras import backend\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Lambda, Input, concatenate,BatchNormalization, Activation, Multiply\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM,Conv1D,MaxPooling1D, Bidirectional, GRU, RepeatVector, TimeDistributed, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set local path of your computer where data files are saved\n",
    "local_path = r'/Users/pablouribepizarro/Desktop/CIAE/CIBL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 11\n"
     ]
    }
   ],
   "source": [
    "files_path = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(local_path+'/Raw/inquiry_lessons'):\n",
    "    for file in f:\n",
    "        if '.xlsx' in file:\n",
    "            files_path.append(os.path.join(r, file))\n",
    "            \n",
    "n_files = len(files_path)\n",
    "print('Total Files: {}'.format(n_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Student</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Number of Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satunnaiskävely.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lukee tehtävänantoa]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Voi voi. [käynnistää videon]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missä se vaeltaa siellä ? Onks se, ei. Ei, se ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[epäselvä]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudentID  Student  time_start  time_end  Phase  Phase_start  Phase_end  \\\n",
       "0        O2      NaN         NaN       NaN      0          1.0        NaN   \n",
       "1        O1      NaN         NaN       NaN      0          NaN        NaN   \n",
       "2        O1      NaN         NaN       NaN      0          NaN        1.0   \n",
       "3        O1      NaN         NaN       NaN      0          1.0        NaN   \n",
       "4        O2      NaN         NaN       NaN      0          NaN        NaN   \n",
       "\n",
       "                                           Utterance  Number of Words  \n",
       "0                                   Satunnaiskävely.                1  \n",
       "1                              [lukee tehtävänantoa]                2  \n",
       "2                       Voi voi. [käynnistää videon]                4  \n",
       "3  Missä se vaeltaa siellä ? Onks se, ei. Ei, se ...               17  \n",
       "4                                         [epäselvä]                1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a list of data frames containing each group's transcription:\n",
    "dfs = []\n",
    "for path in files_path:\n",
    "    df = pd.read_excel(path)\n",
    "    df = df[np.isfinite(df['Phase'])]\n",
    "    df['Phase'] = df['Phase'].astype(int)-1\n",
    "    #Transform raw numbers into digits:\n",
    "    df['Utterance'] = df['Utterance'].apply(lambda row: re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), row))\n",
    "    #Consider '?' as a new word:\n",
    "    df['Utterance'] = df['Utterance'].apply(lambda row: row.replace('?',' ?'))\n",
    "    #Add the number of words:\n",
    "    df['Number of Words'] = df.apply(lambda row: len(row['Utterance'].split()), axis = 1)\n",
    "    dfs.append(df)\n",
    "docs_size = pd.Series([df.shape[0] for df in dfs])\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all documents:\n",
    "docs = [' '.join(list(df['Utterance'].astype(str))) for df in dfs]\n",
    "#Set a tokenizer (the character ? is considered as a new words, thus it is not filtered), only top 2000 words:\n",
    "t = Tokenizer(filters='¡!\"\\'#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',num_words=2000)\n",
    "#Fit the tokenizer:\n",
    "t.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Embeddings\n",
    "from gensim.models import KeyedVectors\n",
    "path = local_path +'/Raw/finnish_4B_parsebank_skgram.bin'\n",
    "wv = KeyedVectors.load_word2vec_format(path,binary=True, encoding='UTF-8',limit=500000,unicode_errors='replace') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Embedding Matrix\n",
    "max_vocab = 10000\n",
    "embedding_matrix = np.zeros((max_vocab, 200))\n",
    "for word, i in t.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = wv.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. MLP (2 hidden Layers) + Pre Trained Static Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set vocab size of the embedding matrix\n",
    "vocab_size = 10000\n",
    "#Set utterance length\n",
    "max_length = 20\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = False\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=False)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "x = Lambda(lambda x: K.sum(x, axis=1))(x)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add Hidden Layers\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "model_1 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.name = 'pe'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_1.save_weights(local_path+'/model_weights/'+str(model_1.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_1.save(local_path+'/models/'+str(model_1.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP (2 hidden Layers) + Pre Trained Trainable Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set vocab size of the embedding matrix\n",
    "vocab_size = 10000\n",
    "#Set utterance length\n",
    "max_length = 20\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = True\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=True)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "x = Lambda(lambda x: K.sum(x, axis=1))(x)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add Hidden Layers\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "model_2 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.name = 'pte'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_2.save_weights(local_path+'/model_weights/'+str(model_2.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_2.save(local_path+'/models/'+str(model_2.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. MLP + Pre Trained Static Embeddings + Simple Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 20\n",
    "\n",
    "from keras.activations import softmax\n",
    "\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = False\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=False)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "#Define the Attention Mechanism:\n",
    "attention = TimeDistributed(Dense(1))\n",
    "attention_weights = attention(x)\n",
    "attention_probs = Activation(softMaxAxis1)(attention_weights)\n",
    "\n",
    "#Multiply Attention Probabilities with the respective embeddings:\n",
    "weighted_encoddings = Lambda(lambda x: x[0] * x[1])([x, attention_probs])\n",
    "\n",
    "#Sum Layer:\n",
    "decoder = Lambda(lambda x: K.sum(x, axis=1))\n",
    "x = decoder(weighted_encoddings)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add a hidden Layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "\n",
    "model_3 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_3.name = 'pe_simple_at'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_3.save_weights(local_path+'/model_weights/'+str(model_3.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_3.save(local_path+'/models/'+str(model_3.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. MLP + Pre Trained Trainable Embeddings + Simple Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 20\n",
    "\n",
    "from keras.activations import softmax\n",
    "\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = True\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=True)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "#Define the Attention Mechanism:\n",
    "attention = TimeDistributed(Dense(1))\n",
    "attention_weights = attention(x)\n",
    "attention_probs = Activation(softMaxAxis1)(attention_weights)\n",
    "\n",
    "#Multiply Attention Probabilities with the respective embeddings:\n",
    "weighted_encoddings = Lambda(lambda x: x[0] * x[1])([x, attention_probs])\n",
    "\n",
    "#Sum Layer:\n",
    "decoder = Lambda(lambda x: K.sum(x, axis=1))\n",
    "x = decoder(weighted_encoddings)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add a hidden Layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "\n",
    "model_3 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_3.name = 'pte_simple_at'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_3.save_weights(local_path+'/model_weights/'+str(model_3.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_3.save(local_path+'/models/'+str(model_3.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. MLP + Pre Trained Static Embeddings + Differentiated Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 20\n",
    "\n",
    "from keras.activations import softmax\n",
    "\n",
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = False\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=False)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "utterances = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "#Differentiated Attention Mechanism\n",
    "\n",
    "attention_1 = TimeDistributed(Dense(1))\n",
    "attention_parameters_1 = attention_1(utterances)\n",
    "attention_weigths_1 = Activation(softMaxAxis1, name = 'attention_1')(attention_parameters_1)\n",
    "\n",
    "weighted_encoddings_1 = Lambda(lambda x: x[0] * x[1])([utterances, attention_weigths_1])\n",
    "\n",
    "attention_2 = TimeDistributed(Dense(1))\n",
    "attention_parameters_2 = attention_2(utterances)\n",
    "attention_weigths_2 = Activation(softMaxAxis1, name = 'attention_2')(attention_parameters_2)\n",
    "\n",
    "weighted_encoddings_2 = Lambda(lambda x: x[0] * x[1])([utterances, attention_weigths_2])\n",
    "\n",
    "attention_3 = TimeDistributed(Dense(1))\n",
    "attention_parameters_3 = attention_3(utterances)\n",
    "attention_weigths_3 = Activation(softMaxAxis1, name = 'attention_3')(attention_parameters_3)\n",
    "\n",
    "weighted_encoddings_3 = Lambda(lambda x: x[0] * x[1])([utterances, attention_weigths_3])\n",
    "\n",
    "attention_4 = TimeDistributed(Dense(1))\n",
    "attention_parameters_4 = attention_4(utterances)\n",
    "attention_weigths_4 = Activation(softMaxAxis1, name = 'attention_4')(attention_parameters_4)\n",
    "\n",
    "weighted_encoddings_4 = Lambda(lambda x: x[0] * x[1])([utterances, attention_weigths_4])\n",
    "\n",
    "attention_5 = TimeDistributed(Dense(1))\n",
    "attention_parameters_5 = attention_5(utterances)\n",
    "attention_weigths_5 = Activation(softMaxAxis1, name = 'attention_5')(attention_parameters_5)\n",
    "\n",
    "weighted_encoddings_5 = Lambda(lambda x: x[0] * x[1])([utterances, attention_weigths_5])\n",
    "\n",
    "#Sum Layer:\n",
    "decoder = Lambda(lambda x: K.sum(x, axis=1))\n",
    "\n",
    "#Output:\n",
    "\n",
    "x_1 = decoder(weighted_encoddings_1)\n",
    "x_1 = concatenate([x_1,rel_position_input,n_words_input])\n",
    "x_1 = Dense(64, activation='relu')(x_1)\n",
    "output_1 = Dense(1, name='output_1')(x_1)\n",
    "\n",
    "x_2 = decoder(weighted_encoddings_2)\n",
    "x_2 = concatenate([x_2,rel_position_input,n_words_input])\n",
    "x_2 = Dense(64, activation='relu')(x_2)\n",
    "output_2 = Dense(1, name='output_2')(x_2)\n",
    "\n",
    "x_3 = decoder(weighted_encoddings_3)\n",
    "x_3 = concatenate([x_3,rel_position_input,n_words_input])\n",
    "x_3 = Dense(64, activation='relu')(x_3)\n",
    "output_3 = Dense(1, name='output_3')(x_3)\n",
    "\n",
    "x_4 = decoder(weighted_encoddings_4)\n",
    "x_4 = concatenate([x_4,rel_position_input,n_words_input])\n",
    "x_4 = Dense(64, activation='relu')(x_4)\n",
    "output_4 = Dense(1,name='output_4')(x_4)\n",
    "\n",
    "x_5 = decoder(weighted_encoddings_5)\n",
    "x_5 = concatenate([x_5,rel_position_input,n_words_input])\n",
    "x_5 = Dense(64, activation='relu')(x_5)\n",
    "output_5 = Dense(1,name='output_5')(x_5)\n",
    "\n",
    "output = concatenate([output_1,output_2,output_3,output_4,output_5])\n",
    "main_output = Activation('softmax', name= 'main_output')(output)\n",
    "\n",
    "model_5 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "\n",
    "model_5.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_5.name = 'pe_dif_at'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_5.save_weights(local_path+'/model_weights/'+str(model_5.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_5.save(local_path+'/models/'+str(model_5.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. MLP (1 Hidden Layer + Dropout) + Pre Trained Static Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set vocab size of the embedding matrix\n",
    "vocab_size = 10000\n",
    "#Set utterance length\n",
    "max_length = 20\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = False\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=False)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "x = Lambda(lambda x: K.sum(x, axis=1))(x)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add One Hidden Layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "model_6 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_6.name = 'pe_1l_do'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_6.save_weights(local_path+'/model_weights/'+str(model_6.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_6.save(local_path+'/models/'+str(model_6.name)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. MLP (1 Hidden Layer + Dropout) + Pre Trained Trainable Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set vocab size of the embedding matrix\n",
    "vocab_size = 10000\n",
    "#Set utterance length\n",
    "max_length = 20\n",
    "\n",
    "#Utterance inputs\n",
    "utterance_input = Input(shape=(max_length,), dtype='int32', name='utterance_input')\n",
    "#Previous\n",
    "previous_utterance_input = Input(shape=(max_length,), dtype='int32', name='p_utterance_input')\n",
    "#Next\n",
    "next_utterance_input = Input(shape=(max_length,), dtype='int32', name='n_utterance_input')\n",
    "\n",
    "#Relative Position input\n",
    "rel_position_input = Input(shape=(1,), dtype='float32', name='rel_position_input')\n",
    "#Number of words input\n",
    "n_words_input = Input(shape=(1,), dtype='float32', name='n_words_input')\n",
    "\n",
    "#Embedding Layer: Trainable = True\n",
    "emb = Embedding(output_dim=200, input_dim=vocab_size, input_length=max_length, weights=[embedding_matrix],trainable=True)\n",
    "\n",
    "embedded_previous = emb(previous_utterance_input)\n",
    "embedded_utterance = emb(utterance_input)\n",
    "embedded_next = emb(next_utterance_input)\n",
    "\n",
    "#Concatenate Previous, Current and Next Utterance Embeddings\n",
    "x = concatenate([embedded_previous,embedded_utterance,embedded_next],axis = 1)\n",
    "\n",
    "x = Lambda(lambda x: K.sum(x, axis=1))(x)\n",
    "\n",
    "#Add the Relative Position and Number of Words Inputs\n",
    "x = concatenate([x,rel_position_input,n_words_input])\n",
    "\n",
    "#Add One Hidden Layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "main_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "\n",
    "model_7 = Model(inputs=[previous_utterance_input,utterance_input,next_utterance_input, \n",
    "                             rel_position_input,n_words_input], outputs=[main_output])\n",
    "model_7.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_7.name = 'pte_1l_do'\n",
    "\n",
    "#Save the random weigths of the model in h5 format\n",
    "model_7.save_weights(local_path+'/model_weights/'+str(model_7.name)+'.h5')\n",
    "#Svae the model in h5 format\n",
    "model_7.save(local_path+'/models/'+str(model_7.name)+'.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
